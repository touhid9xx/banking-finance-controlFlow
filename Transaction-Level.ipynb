{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdc7526",
   "metadata": {},
   "source": [
    "# Transaction-Level Analysis in Banking\n",
    "\n",
    "* In this lesson, we will learn how to explore and analyze individual transactions in a synthetic banking dataset.\n",
    "* Understanding transaction-level data helps banks detect fraud, know their customers, and monitor risk.\n",
    "* You will build practical Python code to uncover trends, unusual spending patterns, and customer insights.\n",
    "* This is a critical skill for working in data roles at banks, fintechs, or credit risk teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7febe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1004b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "   transaction_id customer_id  amount transaction_type channel  \\\n",
      "0               1   CUST_0103  238.77           Credit     ATM   \n",
      "1               2   CUST_0180  269.17           Credit     POS   \n",
      "2               3   CUST_0093   58.62           Credit  Online   \n",
      "\n",
      "                 date  \n",
      "0 2024-01-01 00:00:00  \n",
      "1 2024-01-01 01:00:00  \n",
      "2 2024-01-01 02:00:00  \n"
     ]
    }
   ],
   "source": [
    "# Example 1: Create synthetic banking transactions dataset\n",
    "np.random.seed(42)\n",
    "n_transactions = 1000\n",
    "n_customers = 200\n",
    "df = pd.DataFrame({\n",
    "    'transaction_id': range(1, n_transactions + 1),\n",
    "    'customer_id': np.random.choice([f'CUST_{i:04d}' for i in range(1, n_customers + 1)], n_transactions),\n",
    "    'amount': np.round(np.random.normal(150, 60, n_transactions), 2),\n",
    "    'transaction_type': np.random.choice(['Debit', 'Credit'], n_transactions),\n",
    "    'channel': np.random.choice(['ATM', 'Online', 'Branch', 'POS'], n_transactions),\n",
    "    'date': pd.date_range(start='2024-01-01', periods=n_transactions, freq='h')\n",
    "})\n",
    "print(df.shape)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b5e971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 0\n",
      "Duplicate transaction_id: 0\n"
     ]
    }
   ],
   "source": [
    "# Beginner Example 2: Checking for missing or duplicate transaction_id\n",
    "print('Missing values:', df.isnull().sum().sum())\n",
    "duplicates = df['transaction_id'].duplicated().sum()\n",
    "print('Duplicate transaction_id:', duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422db59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000.000000\n",
      "mean      151.702080\n",
      "std        63.022399\n",
      "min       -64.090000\n",
      "25%       111.372500\n",
      "50%       153.535000\n",
      "75%       195.162500\n",
      "max       340.470000\n",
      "Name: amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Beginner Example 3: Exploring basic statistics for transaction amounts\n",
    "print(df['amount'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4613cc5",
   "metadata": {},
   "source": [
    "# Interpreting Early Results\n",
    "\n",
    "- Transaction amounts can reveal outliers, such as very high or negative values.\n",
    "- Missing or duplicate identifiers usually suggest data entry or pipeline problems.\n",
    "- Comparing transaction counts for each type and channel helps spot suspicious patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f1650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_type\n",
      "Credit    503\n",
      "Debit     497\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Beginner Example 4: Count of transactions by type\n",
    "print(df['transaction_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d7e4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel\n",
      "ATM       266\n",
      "POS       250\n",
      "Branch    248\n",
      "Online    236\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Beginner Example 5: Count transactions by channel\n",
    "print(df['channel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4251b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative or zero transactions: 7\n",
      "     transaction_id  amount\n",
      "94               95   -4.38\n",
      "165             166  -64.09\n"
     ]
    }
   ],
   "source": [
    "# Intermediate Example 1: Find transactions with negative or zero amounts\n",
    "negatives = df[df['amount'] <= 0]\n",
    "print('Number of negative or zero transactions:', negatives.shape[0])\n",
    "print(negatives[['transaction_id', 'amount']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6fae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     transaction_id customer_id  amount\n",
      "92               93   CUST_0111  340.47\n",
      "658             659   CUST_0009  338.52\n",
      "521             522   CUST_0085  335.64\n",
      "535             536   CUST_0096  326.77\n",
      "240             241   CUST_0098  315.65\n"
     ]
    }
   ],
   "source": [
    "# Intermediate Example 2: Top five transactions by amount\n",
    "top5 = df.nlargest(5, 'amount')\n",
    "print(top5[['transaction_id', 'customer_id', 'amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfee6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     transaction_id customer_id  amount\n",
      "165             166   CUST_0170  -64.09\n",
      "819             820   CUST_0165  -53.31\n",
      "297             298   CUST_0161  -12.75\n",
      "312             313   CUST_0128   -8.84\n",
      "231             232   CUST_0068   -4.69\n"
     ]
    }
   ],
   "source": [
    "# Identify the lowest five transactions by amount\n",
    "bottom5 = df.nsmallest(5, 'amount')\n",
    "print(bottom5[['transaction_id', 'customer_id', 'amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512ea5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer with highest total transaction amount: CUST_0099 with amount 1999.1\n"
     ]
    }
   ],
   "source": [
    "# find the customer with the highest total transaction amount\n",
    "customer_totals = df.groupby('customer_id')['amount'].sum() \n",
    "top_customer = customer_totals.idxmax()\n",
    "top_amount = customer_totals.max()  \n",
    "print(f'Customer with highest total transaction amount: {top_customer} with amount {top_amount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c965db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id\n",
      "CUST_0190    13\n",
      "CUST_0099    13\n",
      "CUST_0113    11\n",
      "CUST_0161    11\n",
      "CUST_0090    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## same as above\n",
    "count_per_customer = df['customer_id'].value_counts()\n",
    "print(count_per_customer.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97607d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2024-01-01    3771.76\n",
      "2024-01-02    3993.85\n",
      "2024-01-03    3777.92\n",
      "2024-01-04    3946.69\n",
      "2024-01-05    3489.53\n",
      "Name: amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Intermediate Example 4: Group transactions by date and sum amounts\n",
    "daily_totals = df.groupby(df['date'].dt.date)['amount'].sum()\n",
    "print(daily_totals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ee7b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions flagged as suspicious: 0\n",
      "Empty DataFrame\n",
      "Columns: [transaction_id, customer_id, amount]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Intermediate Example 5: Detect possible suspicious patterns (very high transactions)\n",
    "threshold = df['amount'].mean() + 3 * df['amount'].std()\n",
    "suspicious = df[df['amount'] > threshold]\n",
    "print('Transactions flagged as suspicious:', suspicious.shape[0])\n",
    "print(suspicious[['transaction_id', 'customer_id', 'amount']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af73faad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date day_of_week\n",
      "0 2024-01-01 00:00:00      Monday\n",
      "1 2024-01-01 01:00:00      Monday\n",
      "2 2024-01-01 02:00:00      Monday\n"
     ]
    }
   ],
   "source": [
    "# Intermediate Example 6: Add a day_of_week column for analysis\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "print(df[['date', 'day_of_week']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d190c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id\n",
      "CUST_0099    1999.10\n",
      "CUST_0147    1879.19\n",
      "CUST_0190    1826.46\n",
      "Name: amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Advanced Example 1: Top three customers by total spend\n",
    "total_spend = df.groupby('customer_id')['amount'].sum()\n",
    "top_customers = total_spend.nlargest(3)\n",
    "print(top_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c520c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_type\n",
      "Credit    150.538052\n",
      "Debit     152.880161\n",
      "Name: amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Advanced Example 2: Analyze average debit vs credit amount\n",
    "means = df.groupby('transaction_type')['amount'].mean()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2054aeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id\n",
      "CUST_0161    2\n",
      "CUST_0172    1\n",
      "CUST_0088    1\n",
      "CUST_0050    1\n",
      "CUST_0200    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Advanced Example 3: Find customers with high frequency of small transactions\n",
    "small_tx = df[df['amount'] < 20]\n",
    "small_count = small_tx['customer_id'].value_counts()\n",
    "print(small_count.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fb6f1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    customer_id                date  gap_hours\n",
      "490   CUST_0001 2024-01-21 10:00:00      353.0\n",
      "536   CUST_0001 2024-01-23 08:00:00       46.0\n",
      "709   CUST_0001 2024-01-30 13:00:00      173.0\n",
      "741   CUST_0001 2024-01-31 21:00:00       32.0\n",
      "825   CUST_0001 2024-02-04 09:00:00       84.0\n"
     ]
    }
   ],
   "source": [
    "# Advanced Example 4: Time gap between consecutive customer transactions\n",
    "df_sorted = df.sort_values(['customer_id', 'date'])\n",
    "df_sorted['prev_date'] = df_sorted.groupby('customer_id')['date'].shift(1)\n",
    "df_sorted['gap_hours'] = (df_sorted['date'] - df_sorted['prev_date']).dt.total_seconds() / 3600\n",
    "print(df_sorted[['customer_id', 'date', 'gap_hours']].dropna().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dabba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    238.77\n",
      "1    269.17\n",
      "2     58.62\n",
      "3     81.85\n",
      "4    163.56\n",
      "Name: amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Error Handling: What if the 'amount' column is missing?\n",
    "try:\n",
    "    print(df['amount'].head())\n",
    "except KeyError:\n",
    "    print('Column amount is missing! Please check your data source.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5565c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates are OK!\n"
     ]
    }
   ],
   "source": [
    "# Error Handling: Detect if any date values are missing or out of order\n",
    "if df['date'].isnull().sum() > 0:\n",
    "    print('There are missing dates!')\n",
    "elif not df['date'].is_monotonic_increasing:\n",
    "    print('Dates are not in order!')\n",
    "else:\n",
    "    print('Dates are OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bde7e0",
   "metadata": {},
   "source": [
    "# Best Practices for Transaction Analysis\n",
    "\n",
    "- Always check for missing, duplicated, and out-of-range data before analysis.\n",
    "- Ensure reproducibility by setting random seeds and documenting steps.\n",
    "- Summarize findings using groupby, value_counts, and visualizations.\n",
    "- Time ordering is critical for all fraud and sequence-based analytics.\n",
    "- Keep code modular: write small functions for routine checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dbf35f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0\n",
      "Duplicates: 0\n",
      "Negative Amounts: 7\n",
      "Out-of-order Dates: False\n"
     ]
    }
   ],
   "source": [
    "# Best Practice: Function to summarize key quality checks for transaction DataFrame\n",
    "def transaction_qc(df):\n",
    "    print('Missing:', df.isnull().sum().sum())\n",
    "    print('Duplicates:', df.duplicated().sum())\n",
    "    print('Negative Amounts:', (df['amount'] < 0).sum())\n",
    "    print('Out-of-order Dates:', not df['date'].is_monotonic_increasing)\n",
    "\n",
    "transaction_qc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2b1d3",
   "metadata": {},
   "source": [
    "End-to-End Example: Find Customers with Sudden Spending Surges\n",
    "\n",
    "- Let us walk through a practical use case: flagging customers whose recent spending is much higher than average.\n",
    "- This scenario is common in fraud prevention and credit risk monitoring.\n",
    "- We will group transactions by customer, then compare recent to historical spend.\n",
    "- The steps are: sort by date, compute rolling averages, and highlight surges above a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4fad9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers with surges: 4\n",
      "    customer_id  amount  rolling_avg                date\n",
      "658   CUST_0009  338.52      129.120 2024-01-28 10:00:00\n",
      "866   CUST_0030  254.95      116.736 2024-02-06 02:00:00\n",
      "282   CUST_0129  231.29      114.654 2024-01-12 18:00:00\n",
      "811   CUST_0197  307.75      146.804 2024-02-03 19:00:00\n"
     ]
    }
   ],
   "source": [
    "# End-to-End: Sort, compute rolling mean, and detect surges\n",
    "df_sorted = df.sort_values(['customer_id', 'date'])\n",
    "df_sorted['rolling_avg'] = df_sorted.groupby('customer_id')['amount'].rolling(window=10, min_periods=5).mean().reset_index(level=0, drop=True)\n",
    "df_sorted['spending_surge'] = df_sorted['amount'] > df_sorted['rolling_avg'] * 2\n",
    "surge_cases = df_sorted[df_sorted['spending_surge']]\n",
    "print('Customers with surges:', len(surge_cases['customer_id'].unique()))\n",
    "print(surge_cases[['customer_id', 'amount', 'rolling_avg', 'date']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
